{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate and analyze filtrations for a specified number of PCM instances\n",
    "def generate_filtration_PCM(num_instances=5):\n",
    "    create_new_db = True\n",
    "    # Initialize databases for CL(4) and CL(n) filtrations\n",
    "    db4 = CLFiltrationDB(filepath_generator(dirname=DIR_NAME,filename=f\"{DB_NAME}_4\", extension='db',overwrite=not create_new_db),create_new_db=create_new_db)\n",
    "    dbn = CLFiltrationDB(filepath_generator(dirname=DIR_NAME,filename=f\"{DB_NAME}_n\", extension='db',overwrite=not create_new_db),create_new_db=create_new_db)\n",
    "    \n",
    "    # Extract parameters from configuration for PCM generation\n",
    "    ladder_len_min, ladder_len_max = POINT_CLOUD_PARAMS['ladder_len_min'], POINT_CLOUD_PARAMS['ladder_len_max']\n",
    "    pts_min, pts_max = POINT_CLOUD_PARAMS['pts_min'], POINT_CLOUD_PARAMS['pts_max']\n",
    "    enable_multi_processing, num_cores, verbose = POINT_CLOUD_PARAMS['enable_multi_processing'], POINT_CLOUD_PARAMS['num_cores'], POINT_CLOUD_PARAMS['verbose']\n",
    "    \n",
    "    i = 0\n",
    "    while i < num_instances:  # Loop through the specified number of instances\n",
    "        num_pts = random.randint(pts_min, pts_max)  # Determine the number of points for this model\n",
    "        # Generate a PCM with random filtration\n",
    "        result = RandomFiltrationPointCloudModel(num_pts=num_pts, ladder_length_min=ladder_len_min, ladder_length_max=ladder_len_max, enable_multi_processing=enable_multi_processing, num_cores=num_cores, verbose=verbose)\n",
    "        i += 1\n",
    "        print(i)  # Logging the current instance number\n",
    "        \n",
    "        # Process and store CL(4) filtration results, if present\n",
    "        if filtration := result.output[\"CL(4)\"]:\n",
    "            # Identify non-intervals in the decomposition\n",
    "            non_intervals = {k:v for k,v in filtration.info['decomp'].items() if k[0] == 'N'}\n",
    "            if non_intervals:\n",
    "                print(f'non_intervals found @ {i}', flush=True)\n",
    "                # Send a message indicating non-intervals were found\n",
    "                send_finish_message(f\"non_intervals {non_intervals} found @ {i}, point cloud model, homology dimension: {filtration.info['homology_dim']}.\")\n",
    "            db4.add_filtration(filtration)  # Add filtration results to the database\n",
    "        \n",
    "        # Process and store CL(n) filtration results, if present\n",
    "        if filtration := result.output[\"CL(n)\"]:\n",
    "            # Check for non-intervals in CL(n) results\n",
    "            non_intervals = (pd.read_csv(StringIO(filtration.info['lines']), index_col=0).multiplicity < 0).any()\n",
    "            if non_intervals:\n",
    "                # Send a message indicating non-intervals were found in CL(n) results\n",
    "                send_finish_message(f\"non_intervals {filtration.info['lines']} found @ {i}, point cloud model, homology dimension: {filtration.info['homology_dim']}, ladder_length: {filtration.ladder_length}.\")\n",
    "            dbn.add_filtration(filtration)  # Add CL(n) filtration results to the database\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
